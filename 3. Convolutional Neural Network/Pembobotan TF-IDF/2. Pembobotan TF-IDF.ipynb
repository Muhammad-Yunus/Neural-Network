{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['lisaamartatara', 'fadlizon', 'bangga', 'bang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['rustamibrahim', 'polling', 'gubernur', 'jawa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>['ojok', 'ampe', 'anies', 'baswedan', 'nikmat'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['ghanieierfan', 'temu', 'haru', 'aniesbasweda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>['sebastianteza', 'jangn', 'nympek', 'anies', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      1  ['lisaamartatara', 'fadlizon', 'bangga', 'bang...\n",
       "1      1  ['rustamibrahim', 'polling', 'gubernur', 'jawa...\n",
       "2      1  ['ojok', 'ampe', 'anies', 'baswedan', 'nikmat'...\n",
       "3      0  ['ghanieierfan', 'temu', 'haru', 'aniesbasweda...\n",
       "4      1  ['sebastianteza', 'jangn', 'nympek', 'anies', ..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "TWEET_DATA = pd.read_csv(\"Text_Preprocessing_v2.csv\", usecols=[\"label\", \"tweet_tokens_stemmed\"])\n",
    "TWEET_DATA.columns = [\"label\", \"tweet\"]\n",
    "\n",
    "TWEET_DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['idtodayco', 'media', 'bungkam', 'tutup', 'dampak', 'banjir', 'jateng', 'gubernur', 'pdipnhttpstcoxoamyep']\n",
      "\n",
      "type :  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# convert list formated string to list\n",
    "import ast\n",
    "\n",
    "def convert_text_list(texts):\n",
    "    texts = ast.literal_eval(texts)\n",
    "    return [text for text in texts]\n",
    "\n",
    "TWEET_DATA[\"tweet_list\"] = TWEET_DATA[\"tweet\"].apply(convert_text_list)\n",
    "\n",
    "\n",
    "print(TWEET_DATA[\"tweet_list\"][90])\n",
    "\n",
    "print(\"\\ntype : \", type(TWEET_DATA[\"tweet_list\"][90]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'maspiyuuu': 0.07142857142857142, 'bantu': 0....\n",
       "1    {'lisaamartatara': 0.07142857142857142, 'fadli...\n",
       "2    {'rustamibrahim': 0.07142857142857142, 'pollin...\n",
       "3    {'ojok': 0.08333333333333333, 'ampe': 0.083333...\n",
       "4    {'ghanieierfan': 0.07692307692307693, 'temu': ...\n",
       "Name: TF_dict, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_TF(document):\n",
    "    # Counts the number of times the word appears in review\n",
    "    TF_dict = {}\n",
    "    for term in document:\n",
    "        if term in TF_dict:\n",
    "            TF_dict[term] += 1\n",
    "        else:\n",
    "            TF_dict[term] = 1\n",
    "    # Computes tf for each word\n",
    "    for term in TF_dict:\n",
    "        TF_dict[term] = TF_dict[term] / len(document)\n",
    "    return TF_dict\n",
    "\n",
    "TWEET_DATA[\"TF_dict\"] = TWEET_DATA['tweet_list'].apply(calc_TF)\n",
    "\n",
    "TWEET_DATA[\"TF_dict\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                term \t TF\n",
      "\n",
      "       geiszchalifah \t 0.047619047619047616\n",
      "              bangun \t 0.09523809523809523\n",
      "                 era \t 0.047619047619047616\n",
      "               anies \t 0.047619047619047616\n",
      "             penting \t 0.047619047619047616\n",
      "          masyarakat \t 0.047619047619047616\n",
      "              gratis \t 0.047619047619047616\n",
      "                 utk \t 0.047619047619047616\n",
      "              rakyat \t 0.047619047619047616\n",
      "                uang \t 0.047619047619047616\n",
      "                 nya \t 0.047619047619047616\n",
      "                  dr \t 0.047619047619047616\n",
      "               nbeda \t 0.047619047619047616\n",
      "                 ono \t 0.047619047619047616\n",
      "                 kpd \t 0.047619047619047616\n",
      "                 amp \t 0.047619047619047616\n",
      "              untung \t 0.047619047619047616\n",
      "              cukong \t 0.047619047619047616\n",
      "            nmakanya \t 0.047619047619047616\n",
      "           downgrade \t 0.047619047619047616\n"
     ]
    }
   ],
   "source": [
    "# Check TF result\n",
    "index = 90\n",
    "\n",
    "print('%20s' % \"term\", \"\\t\", \"TF\\n\")\n",
    "for key in TWEET_DATA[\"TF_dict\"][index]:\n",
    "    print('%20s' % key, \"\\t\", TWEET_DATA[\"TF_dict\"][index][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_DF(tfDict):\n",
    "    count_DF = {}\n",
    "    # Run through each document's tf dictionary and increment countDict's (term, doc) pair\n",
    "    for document in tfDict:\n",
    "        for term in document:\n",
    "            if term in count_DF:\n",
    "                count_DF[term] += 1\n",
    "            else:\n",
    "                count_DF[term] = 1\n",
    "    return count_DF\n",
    "\n",
    "DF = calc_DF(TWEET_DATA[\"TF_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_document = len(TWEET_DATA)\n",
    "\n",
    "def calc_IDF(__n_document, __DF):\n",
    "    IDF_Dict = {}\n",
    "    for term in __DF:\n",
    "        IDF_Dict[term] = np.log(__n_document / (__DF[term] + 1))\n",
    "    return IDF_Dict\n",
    "  \n",
    "#Stores the idf dictionary\n",
    "IDF = calc_IDF(n_document, DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc TF-IDF\n",
    "def calc_TF_IDF(TF):\n",
    "    TF_IDF_Dict = {}\n",
    "    #For each word in the review, we multiply its tf and its idf.\n",
    "    for key in TF:\n",
    "        TF_IDF_Dict[key] = TF[key] * IDF[key]\n",
    "    return TF_IDF_Dict\n",
    "\n",
    "#Stores the TF-IDF Series\n",
    "TWEET_DATA[\"TF-IDF_dict\"] = TWEET_DATA[\"TF_dict\"].apply(calc_TF_IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                term \t         TF \t              TF-IDF\n",
      "\n",
      "       geiszchalifah \t 0.047619047619047616 \t 0.3565731050581192\n",
      "              bangun \t 0.09523809523809523 \t 0.4547495147096688\n",
      "                 era \t 0.047619047619047616 \t 0.28295765235755843\n",
      "               anies \t 0.047619047619047616 \t 0.15689952663115753\n",
      "             penting \t 0.047619047619047616 \t 0.2649689616166619\n",
      "          masyarakat \t 0.047619047619047616 \t 0.20988274600184767\n",
      "              gratis \t 0.047619047619047616 \t 0.3183661301759793\n",
      "                 utk \t 0.047619047619047616 \t 0.19737626788157656\n",
      "              rakyat \t 0.047619047619047616 \t 0.17481754982266384\n",
      "                uang \t 0.047619047619047616 \t 0.2322302300527719\n",
      "                 nya \t 0.047619047619047616 \t 0.1754665417776927\n",
      "                  dr \t 0.047619047619047616 \t 0.21247607538910393\n",
      "               nbeda \t 0.047619047619047616 \t 0.426398679762568\n",
      "                 ono \t 0.047619047619047616 \t 0.3860511626012727\n",
      "                 kpd \t 0.047619047619047616 \t 0.26715872891389153\n",
      "                 amp \t 0.047619047619047616 \t 0.1677888440676102\n",
      "              untung \t 0.047619047619047616 \t 0.2737580700227557\n",
      "              cukong \t 0.047619047619047616 \t 0.3565731050581192\n",
      "            nmakanya \t 0.047619047619047616 \t 0.40207365005942564\n",
      "           downgrade \t 0.047619047619047616 \t 0.4457065420534331\n"
     ]
    }
   ],
   "source": [
    "# Check TF-IDF result\n",
    "index = 90\n",
    "\n",
    "print('%20s' % \"term\", \"\\t\", '%10s' % \"TF\", \"\\t\", '%20s' % \"TF-IDF\\n\")\n",
    "for key in TWEET_DATA[\"TF-IDF_dict\"][index]:\n",
    "    print('%20s' % key, \"\\t\", TWEET_DATA[\"TF_dict\"][index][key] ,\"\\t\" , TWEET_DATA[\"TF-IDF_dict\"][index][key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print first row matrix TF_IDF_Vec Series\n",
      "\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2199601102972785, 0.0, 0.0, 0.22999663077827417, 0.0, 0.2353492899467363, 0.0, 0.0, 0.0, 0.2503403900656905, 0.0, 0.0, 0.2565368848091658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29783301251384003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "matrix size :  50\n"
     ]
    }
   ],
   "source": [
    "# sort descending by value for DF dictionary \n",
    "sorted_DF = sorted(DF.items(), key=lambda kv: kv[1], reverse=True)[:50]\n",
    "\n",
    "# Create a list of unique words from sorted dictionay `sorted_DF`\n",
    "unique_term = [item[0] for item in sorted_DF]\n",
    "\n",
    "def calc_TF_IDF_Vec(__TF_IDF_Dict):\n",
    "    TF_IDF_vector = [0.0] * len(unique_term)\n",
    "\n",
    "    # For each unique word, if it is in the review, store its TF-IDF value.\n",
    "    for i, term in enumerate(unique_term):\n",
    "        if term in __TF_IDF_Dict:\n",
    "            TF_IDF_vector[i] = __TF_IDF_Dict[term]\n",
    "    return TF_IDF_vector\n",
    "\n",
    "TWEET_DATA[\"TF_IDF_Vec\"] = TWEET_DATA[\"TF-IDF_dict\"].apply(calc_TF_IDF_Vec)\n",
    "\n",
    "print(\"print first row matrix TF_IDF_Vec Series\\n\")\n",
    "print(TWEET_DATA[\"TF_IDF_Vec\"][0])\n",
    "\n",
    "print(\"\\nmatrix size : \", len(TWEET_DATA[\"TF_IDF_Vec\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jokowi</td>\n",
       "      <td>885.006775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banjir</td>\n",
       "      <td>392.070549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nkri</td>\n",
       "      <td>342.263361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bakar</td>\n",
       "      <td>329.048630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aniesbaswedan</td>\n",
       "      <td>316.057243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hutan</td>\n",
       "      <td>314.320327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>300.811656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ya</td>\n",
       "      <td>277.269327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jakarta</td>\n",
       "      <td>274.140503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>anies</td>\n",
       "      <td>262.612076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aja</td>\n",
       "      <td>251.041999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gak</td>\n",
       "      <td>249.411101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>presiden</td>\n",
       "      <td>245.101117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>orang</td>\n",
       "      <td>230.837029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>corona</td>\n",
       "      <td>224.442791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>negara</td>\n",
       "      <td>213.513163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ga</td>\n",
       "      <td>209.575982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>msaiddidu</td>\n",
       "      <td>209.542224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>perintah</td>\n",
       "      <td>202.465924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rakyat</td>\n",
       "      <td>193.019303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kerja</td>\n",
       "      <td>188.713790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>warga</td>\n",
       "      <td>183.754070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gubernur</td>\n",
       "      <td>177.024590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nya</td>\n",
       "      <td>175.462331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>virus</td>\n",
       "      <td>168.773347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>amp</td>\n",
       "      <td>167.162915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>salah</td>\n",
       "      <td>165.507991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rusuh</td>\n",
       "      <td>160.841564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>australia</td>\n",
       "      <td>160.055933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>harga</td>\n",
       "      <td>159.244521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>who</td>\n",
       "      <td>156.611799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tangan</td>\n",
       "      <td>152.701559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mati</td>\n",
       "      <td>152.292047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>korban</td>\n",
       "      <td>144.037130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kalo</td>\n",
       "      <td>143.417109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>masuk</td>\n",
       "      <td>143.211934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>moga</td>\n",
       "      <td>142.784437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>dukung</td>\n",
       "      <td>141.008167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pimpin</td>\n",
       "      <td>139.221205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>udah</td>\n",
       "      <td>137.977505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>jiwasraya</td>\n",
       "      <td>136.484806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>dki</td>\n",
       "      <td>132.956698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>biar</td>\n",
       "      <td>128.563759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>bantu</td>\n",
       "      <td>127.966475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tau</td>\n",
       "      <td>127.646984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>bikin</td>\n",
       "      <td>126.097358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>air</td>\n",
       "      <td>119.816476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>utk</td>\n",
       "      <td>115.931367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sdh</td>\n",
       "      <td>110.790841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tdk</td>\n",
       "      <td>107.545177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term        rank\n",
       "0          jokowi  885.006775\n",
       "1          banjir  392.070549\n",
       "3            nkri  342.263361\n",
       "2           bakar  329.048630\n",
       "4   aniesbaswedan  316.057243\n",
       "5           hutan  314.320327\n",
       "6       indonesia  300.811656\n",
       "8              ya  277.269327\n",
       "7         jakarta  274.140503\n",
       "11          anies  262.612076\n",
       "9             aja  251.041999\n",
       "10            gak  249.411101\n",
       "13       presiden  245.101117\n",
       "12          orang  230.837029\n",
       "17         corona  224.442791\n",
       "15         negara  213.513163\n",
       "14             ga  209.575982\n",
       "29      msaiddidu  209.542224\n",
       "19       perintah  202.465924\n",
       "21         rakyat  193.019303\n",
       "20          kerja  188.713790\n",
       "18          warga  183.754070\n",
       "23       gubernur  177.024590\n",
       "22            nya  175.462331\n",
       "24          virus  168.773347\n",
       "16            amp  167.162915\n",
       "25          salah  165.507991\n",
       "33          rusuh  160.841564\n",
       "26      australia  160.055933\n",
       "35          harga  159.244521\n",
       "32            who  156.611799\n",
       "31         tangan  152.701559\n",
       "36           mati  152.292047\n",
       "28         korban  144.037130\n",
       "27           kalo  143.417109\n",
       "38          masuk  143.211934\n",
       "48           moga  142.784437\n",
       "45         dukung  141.008167\n",
       "42         pimpin  139.221205\n",
       "34           udah  137.977505\n",
       "46      jiwasraya  136.484806\n",
       "30            dki  132.956698\n",
       "44           biar  128.563759\n",
       "43          bantu  127.966475\n",
       "37            tau  127.646984\n",
       "49          bikin  126.097358\n",
       "39            air  119.816476\n",
       "40            utk  115.931367\n",
       "47            sdh  110.790841\n",
       "41            tdk  107.545177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Series to List\n",
    "TF_IDF_Vec_List = np.array(TWEET_DATA[\"TF_IDF_Vec\"].to_list())\n",
    "\n",
    "# Sum element vector in axis=0 \n",
    "sums = TF_IDF_Vec_List.sum(axis=0)\n",
    "\n",
    "data = []\n",
    "\n",
    "for col, term in enumerate(unique_term):\n",
    "    data.append((term, sums[col]))\n",
    "    \n",
    "ranking = pd.DataFrame(data, columns=['term', 'rank'])\n",
    "ranking.sort_values('rank', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "# TF-IDF menggunakan Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['maspiyuuu', 'bantu', 'bekas', 'anies', 'basw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['lisaamartatara', 'fadlizon', 'bangga', 'bang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>['rustamibrahim', 'polling', 'gubernur', 'jawa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>['ojok', 'ampe', 'anies', 'baswedan', 'nikmat'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['ghanieierfan', 'temu', 'haru', 'aniesbasweda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      0  ['maspiyuuu', 'bantu', 'bekas', 'anies', 'basw...\n",
       "1      1  ['lisaamartatara', 'fadlizon', 'bangga', 'bang...\n",
       "2      1  ['rustamibrahim', 'polling', 'gubernur', 'jawa...\n",
       "3      1  ['ojok', 'ampe', 'anies', 'baswedan', 'nikmat'...\n",
       "4      0  ['ghanieierfan', 'temu', 'haru', 'aniesbasweda..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "TWEET_DATA = pd.read_csv(\"Text_Preprocessing.csv\", usecols=[\"label\", \"tweet_tokens_stemmed\"])\n",
    "TWEET_DATA.columns = [\"label\", \"tweet\"]\n",
    "\n",
    "TWEET_DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    maspiyuuu bantu bekas anies baswedan layan war...\n",
       "1    lisaamartatara fadlizon bangga banggain buzzer...\n",
       "2    rustamibrahim polling gubernur jawa ridwan kam...\n",
       "3    ojok ampe anies baswedan nikmat hsil proyek mo...\n",
       "4    ghanieierfan temu haru aniesbaswedan tsuneo ya...\n",
       "Name: tweet_join, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join list of token as single document string\n",
    "import ast\n",
    "\n",
    "def join_text_list(texts):\n",
    "    texts = ast.literal_eval(texts)\n",
    "    return ' '.join([text for text in texts])\n",
    "TWEET_DATA[\"tweet_join\"] = TWEET_DATA[\"tweet\"].apply(join_text_list)\n",
    "\n",
    "TWEET_DATA[\"tweet_join\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Scikit-Learn L2 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- TF-IDF on Tweet data -------\n",
      "TF-IDF  <class 'numpy.ndarray'> (23225, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# banyaknya term yang akan digunakan, \n",
    "# di pilih berdasarkan top max_features \n",
    "# yang diurutkan berdasarkan term frequency seluruh corpus\n",
    "max_features = 1000\n",
    "\n",
    "# Feature Engineering \n",
    "print (\"------- TF-IDF on Tweet data -------\")\n",
    "\n",
    "tf_idf = TfidfVectorizer(max_features=max_features, binary=True)\n",
    "tfidf_mat = tf_idf.fit_transform(TWEET_DATA[\"tweet_join\"]).toarray()\n",
    "\n",
    "print(\"TF-IDF \", type(tfidf_mat), tfidf_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_idf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-b9ae52297616>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mterms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_idf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# sum tfidf frequency of each term through documents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_mat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_idf' is not defined"
     ]
    }
   ],
   "source": [
    "terms = tf_idf.get_feature_names()\n",
    "\n",
    "# sum tfidf frequency of each term through documents\n",
    "sums = tfidf_mat.sum(axis=0)\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "data = []\n",
    "for col, term in enumerate(terms):\n",
    "    data.append((term, sums[col] ))\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','rank'])\n",
    "ranking.sort_values('rank', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Scikit-Learn L1 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "max_features = 1000\n",
    "\n",
    "# calc TF vector\n",
    "cvect = CountVectorizer(max_features=max_features)\n",
    "TF_vector = cvect.fit_transform(TWEET_DATA[\"tweet_join\"])\n",
    "\n",
    "# normalize TF vector\n",
    "normalized_TF_vector = normalize(TF_vector, norm='l1', axis=1)\n",
    "\n",
    "# calc IDF\n",
    "tfidf = TfidfVectorizer(max_features=max_features, smooth_idf=False)\n",
    "tfs = tfidf.fit_transform(TWEET_DATA[\"tweet_join\"])\n",
    "IDF_vector = tfidf.idf_\n",
    "\n",
    "# hitung TF x IDF sehingga dihasilkan TFIDF matrix / vector\n",
    "tfidf_mat = normalized_TF_vector.multiply(IDF_vector).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Scikit-Learn L1 Norm unigram, bigram, trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "max_features = 1000\n",
    "\n",
    "# ngram_range (1, 3) to use unigram, bigram, trigram\n",
    "cvect = CountVectorizer(max_features=max_features, ngram_range=(1,3))\n",
    "counts = cvect.fit_transform(TWEET_DATA[\"tweet_join\"])\n",
    "\n",
    "normalized_counts = normalize(counts, norm='l1', axis=1)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=max_features, ngram_range=(1,3), smooth_idf=False)\n",
    "tfs = tfidf.fit_transform(TWEET_DATA[\"tweet_join\"])\n",
    "\n",
    "tfidf_mat = normalized_counts.multiply(tfidf.idf_).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF vector unigram only / bigram only / trigram only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "max_features = 1000\n",
    "\n",
    "\n",
    "def generate_tfidf_mat(min_gram, max_gram):\n",
    "    cvect = CountVectorizer(max_features=max_features, ngram_range=(min_gram, max_gram))\n",
    "    counts = cvect.fit_transform(TWEET_DATA[\"tweet_join\"])\n",
    "\n",
    "    normalized_counts = normalize(counts, norm='l1', axis=1)\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_features=max_features, ngram_range=(min_gram, max_gram), smooth_idf=False)\n",
    "    tfs = tfidf.fit_transform(TWEET_DATA[\"tweet_join\"])\n",
    "\n",
    "    tfidf_mat = normalized_counts.multiply(tfidf.idf_).toarray()\n",
    "    \n",
    "    TF = normalized_counts.toarray()\n",
    "    IDF = tfidf.idf_\n",
    "    TF_IDF = tfidf_mat\n",
    "    return TF, IDF, TF_IDF, tfidf.get_feature_names()\n",
    "\n",
    "# ngram_range (1, 1) to use unigram only\n",
    "tf_mat_unigram, idf_mat_unigram, tfidf_mat_unigram, terms_unigram = generate_tfidf_mat(1,1)\n",
    "\n",
    "# ngram_range (2, 2) to use bigram only\n",
    "tf_mat_bigram, idf_mat_bigram, tfidf_mat_bigram, terms_bigram = generate_tfidf_mat(2,2)\n",
    "\n",
    "# ngram_range (3, 3) to use trigram only\n",
    "tf_mat_trigram, idf_mat_trigram, tfidf_mat_bigram, terms_trigram = generate_tfidf_mat(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print tf-idf unigram\n",
    "tfidf_mat_unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show TFIDF sample ke-0 \n",
      "\n",
      "['maspiyuuu', 'bantu', 'bekas', 'anies', 'baswedan', 'layan', 'warga', 'negara', 'indonesia', 'httpstcobiwxvhsvknntinggal', 'lantik', 'aja', 'inimah', 'pru'] \n",
      "\n",
      "\t\t\t TF \t\t IDF \t\t TF-IDF \t Term\n",
      "\n",
      "array position 15\t 0.100000 \t 4.219953 \t 0.421995 \t aja\n",
      "array position 50\t 0.100000 \t 4.296052 \t 0.429605 \t anies\n",
      "array position 104\t 0.100000 \t 5.172452 \t 0.517245 \t bantu\n",
      "array position 108\t 0.100000 \t 5.507807 \t 0.550781 \t baswedan\n",
      "array position 118\t 0.100000 \t 6.975447 \t 0.697545 \t bekas\n",
      "array position 358\t 0.100000 \t 4.080378 \t 0.408038 \t indonesia\n",
      "array position 520\t 0.100000 \t 6.942111 \t 0.694211 \t layan\n",
      "array position 566\t 0.100000 \t 6.658535 \t 0.665854 \t maspiyuuu\n",
      "array position 624\t 0.100000 \t 4.504765 \t 0.450477 \t negara\n",
      "array position 981\t 0.100000 \t 4.593080 \t 0.459308 \t warga\n"
     ]
    }
   ],
   "source": [
    "idx_sample = 0\n",
    "\n",
    "print(\"Show TFIDF sample ke-\" + str(idx_sample), \"\\n\")\n",
    "print(TWEET_DATA[\"tweet\"][idx_sample], \"\\n\")\n",
    "\n",
    "print(\"\\t\\t\\t\", \"TF\", \"\\t\\t\", \"IDF\", \"\\t\\t\", \"TF-IDF\", \"\\t\", \"Term\\n\")\n",
    "for i, item in enumerate(zip(tf_mat_unigram[idx_sample], idf_mat_unigram, tfidf_mat_unigram[idx_sample], terms_unigram)):\n",
    "    if(item[2] != 0.0):\n",
    "        print (\"array position \" + str(i) + \"\\t\", \n",
    "               \"%.6f\" % item[0], \"\\t\", \n",
    "               \"%.6f\" % item[1], \"\\t\", \n",
    "               \"%.6f\" % item[2], \"\\t\", \n",
    "               item[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23225, 1000), (23225, 1000), (1000,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check Matrix size\n",
    "\n",
    "tf_mat_unigram.shape, tfidf_mat_unigram.shape, idf_mat_unigram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>TF_UNIGRAM</th>\n",
       "      <th>IDF_UNIGRAM</th>\n",
       "      <th>TFIDF_UNIGRAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['maspiyuuu', 'bantu', 'bekas', 'anies', 'basw...</td>\n",
       "      <td>[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...</td>\n",
       "      <td>[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...</td>\n",
       "      <td>[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['lisaamartatara', 'fadlizon', 'bangga', 'bang...</td>\n",
       "      <td>[0.16666666666666666, 0.16666666666666666, 0.1...</td>\n",
       "      <td>[0.16666666666666666, 0.16666666666666666, 0.1...</td>\n",
       "      <td>[0.16666666666666666, 0.16666666666666666, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['rustamibrahim', 'polling', 'gubernur', 'jawa...</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['ojok', 'ampe', 'anies', 'baswedan', 'nikmat'...</td>\n",
       "      <td>[0.14285714285714285, 0.14285714285714285, 0.1...</td>\n",
       "      <td>[0.14285714285714285, 0.14285714285714285, 0.1...</td>\n",
       "      <td>[0.14285714285714285, 0.14285714285714285, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ghanieierfan', 'temu', 'haru', 'aniesbasweda...</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  ['maspiyuuu', 'bantu', 'bekas', 'anies', 'basw...   \n",
       "1  ['lisaamartatara', 'fadlizon', 'bangga', 'bang...   \n",
       "2  ['rustamibrahim', 'polling', 'gubernur', 'jawa...   \n",
       "3  ['ojok', 'ampe', 'anies', 'baswedan', 'nikmat'...   \n",
       "4  ['ghanieierfan', 'temu', 'haru', 'aniesbasweda...   \n",
       "\n",
       "                                          TF_UNIGRAM  \\\n",
       "0  [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...   \n",
       "1  [0.16666666666666666, 0.16666666666666666, 0.1...   \n",
       "2                           [0.25, 0.25, 0.25, 0.25]   \n",
       "3  [0.14285714285714285, 0.14285714285714285, 0.1...   \n",
       "4                           [0.25, 0.25, 0.25, 0.25]   \n",
       "\n",
       "                                         IDF_UNIGRAM  \\\n",
       "0  [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...   \n",
       "1  [0.16666666666666666, 0.16666666666666666, 0.1...   \n",
       "2                           [0.25, 0.25, 0.25, 0.25]   \n",
       "3  [0.14285714285714285, 0.14285714285714285, 0.1...   \n",
       "4                           [0.25, 0.25, 0.25, 0.25]   \n",
       "\n",
       "                                       TFIDF_UNIGRAM  \n",
       "0  [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, ...  \n",
       "1  [0.16666666666666666, 0.16666666666666666, 0.1...  \n",
       "2                           [0.25, 0.25, 0.25, 0.25]  \n",
       "3  [0.14285714285714285, 0.14285714285714285, 0.1...  \n",
       "4                           [0.25, 0.25, 0.25, 0.25]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_TF_unigram(row):\n",
    "    idx = row.name\n",
    "    return [tf for tf in tf_mat_unigram[idx] if tf != 0.0]\n",
    "\n",
    "TWEET_DATA[\"TF_UNIGRAM\"] = TWEET_DATA.apply(get_TF_unigram, axis=1)\n",
    "\n",
    "def get_IDF_unigram(row):\n",
    "    idx = row.name\n",
    "    return [item[1] for item in zip(tf_mat_unigram[idx], idf_mat_unigram) if item[0] != 0.0]\n",
    "\n",
    "TWEET_DATA[\"IDF_UNIGRAM\"] = TWEET_DATA.apply(get_TF_unigram, axis=1)\n",
    "\n",
    "def get_TFIDF_unigram(row):\n",
    "    idx = row.name\n",
    "    return [tfidf for tfidf in tfidf_mat_unigram if tfidf != 0.0]\n",
    "\n",
    "TWEET_DATA[\"TFIDF_UNIGRAM\"] = TWEET_DATA.apply(get_TF_unigram, axis=1)\n",
    "\n",
    "TWEET_DATA[[\"tweet\", \"TF_UNIGRAM\", \"IDF_UNIGRAM\", \"TFIDF_UNIGRAM\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TFIDF Unigram to Excel\n",
    "\n",
    "TWEET_DATA[[\"tweet\", \"TF_UNIGRAM\", \"IDF_UNIGRAM\", \"TFIDF_UNIGRAM\"]].to_excel(\"TFIDF_Unigram.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>TF_BIGRAM</th>\n",
       "      <th>IDF_BIGRAM</th>\n",
       "      <th>TFIDF_BIGRAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['maspiyuuu', 'bantu', 'bekas', 'anies', 'basw...</td>\n",
       "      <td>[0.3333333333333333, 0.3333333333333333, 0.333...</td>\n",
       "      <td>[0.3333333333333333, 0.3333333333333333, 0.333...</td>\n",
       "      <td>[0.3333333333333333, 0.3333333333333333, 0.333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['lisaamartatara', 'fadlizon', 'bangga', 'bang...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['rustamibrahim', 'polling', 'gubernur', 'jawa...</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['ojok', 'ampe', 'anies', 'baswedan', 'nikmat'...</td>\n",
       "      <td>[0.14285714285714285, 0.14285714285714285, 0.1...</td>\n",
       "      <td>[0.14285714285714285, 0.14285714285714285, 0.1...</td>\n",
       "      <td>[0.14285714285714285, 0.14285714285714285, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ghanieierfan', 'temu', 'haru', 'aniesbasweda...</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  ['maspiyuuu', 'bantu', 'bekas', 'anies', 'basw...   \n",
       "1  ['lisaamartatara', 'fadlizon', 'bangga', 'bang...   \n",
       "2  ['rustamibrahim', 'polling', 'gubernur', 'jawa...   \n",
       "3  ['ojok', 'ampe', 'anies', 'baswedan', 'nikmat'...   \n",
       "4  ['ghanieierfan', 'temu', 'haru', 'aniesbasweda...   \n",
       "\n",
       "                                           TF_BIGRAM  \\\n",
       "0  [0.3333333333333333, 0.3333333333333333, 0.333...   \n",
       "1                                                 []   \n",
       "2                                              [1.0]   \n",
       "3  [0.14285714285714285, 0.14285714285714285, 0.1...   \n",
       "4                                              [1.0]   \n",
       "\n",
       "                                          IDF_BIGRAM  \\\n",
       "0  [0.3333333333333333, 0.3333333333333333, 0.333...   \n",
       "1                                                 []   \n",
       "2                                              [1.0]   \n",
       "3  [0.14285714285714285, 0.14285714285714285, 0.1...   \n",
       "4                                              [1.0]   \n",
       "\n",
       "                                        TFIDF_BIGRAM  \n",
       "0  [0.3333333333333333, 0.3333333333333333, 0.333...  \n",
       "1                                                 []  \n",
       "2                                              [1.0]  \n",
       "3  [0.14285714285714285, 0.14285714285714285, 0.1...  \n",
       "4                                              [1.0]  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_TF_bigram(row):\n",
    "    idx = row.name\n",
    "    return [tf for tf in tf_mat_bigram[idx] if tf != 0.0]\n",
    "\n",
    "TWEET_DATA[\"TF_BIGRAM\"] = TWEET_DATA.apply(get_TF_bigram, axis=1)\n",
    "\n",
    "def get_IDF_bigram(row):\n",
    "    idx = row.name\n",
    "    return [item[1] for item in zip(tf_mat_bigram[idx], idf_mat_bigram) if item[0] != 0.0]\n",
    "\n",
    "TWEET_DATA[\"IDF_BIGRAM\"] = TWEET_DATA.apply(get_TF_bigram, axis=1)\n",
    "\n",
    "def get_TFIDF_bigram(row):\n",
    "    idx = row.name\n",
    "    return [tfidf for tfidf in tfidf_mat_bigram if tfidf != 0.0]\n",
    "\n",
    "TWEET_DATA[\"TFIDF_BIGRAM\"] = TWEET_DATA.apply(get_TF_bigram, axis=1)\n",
    "\n",
    "TWEET_DATA[[\"tweet\", \"TF_BIGRAM\", \"IDF_BIGRAM\", \"TFIDF_BIGRAM\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TFIDF Bigram to Excel\n",
    "\n",
    "TWEET_DATA[[\"tweet\", \"TF_BIGRAM\", \"IDF_BIGRAM\", \"TFIDF_BIGRAM\"]].to_excel(\"TFIDF_Bigram.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>TF_trigram</th>\n",
       "      <th>IDF_trigram</th>\n",
       "      <th>TFIDF_trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['maspiyuuu', 'bantu', 'bekas', 'anies', 'basw...</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['lisaamartatara', 'fadlizon', 'bangga', 'bang...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['rustamibrahim', 'polling', 'gubernur', 'jawa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['ojok', 'ampe', 'anies', 'baswedan', 'nikmat'...</td>\n",
       "      <td>[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.1...</td>\n",
       "      <td>[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.1...</td>\n",
       "      <td>[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ghanieierfan', 'temu', 'haru', 'aniesbasweda...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  ['maspiyuuu', 'bantu', 'bekas', 'anies', 'basw...   \n",
       "1  ['lisaamartatara', 'fadlizon', 'bangga', 'bang...   \n",
       "2  ['rustamibrahim', 'polling', 'gubernur', 'jawa...   \n",
       "3  ['ojok', 'ampe', 'anies', 'baswedan', 'nikmat'...   \n",
       "4  ['ghanieierfan', 'temu', 'haru', 'aniesbasweda...   \n",
       "\n",
       "                                          TF_trigram  \\\n",
       "0                                              [1.0]   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.1...   \n",
       "4                                                 []   \n",
       "\n",
       "                                         IDF_trigram  \\\n",
       "0                                              [1.0]   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.1...   \n",
       "4                                                 []   \n",
       "\n",
       "                                       TFIDF_trigram  \n",
       "0                                              [1.0]  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3  [0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.1...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_TF_trigram(row):\n",
    "    idx = row.name\n",
    "    return [tf for tf in tf_mat_trigram[idx] if tf != 0.0]\n",
    "\n",
    "TWEET_DATA[\"TF_trigram\"] = TWEET_DATA.apply(get_TF_trigram, axis=1)\n",
    "\n",
    "def get_IDF_trigram(row):\n",
    "    idx = row.name\n",
    "    return [item[1] for item in zip(tf_mat_trigram[idx], idf_mat_trigram) if item[0] != 0.0]\n",
    "\n",
    "TWEET_DATA[\"IDF_trigram\"] = TWEET_DATA.apply(get_TF_trigram, axis=1)\n",
    "\n",
    "def get_TFIDF_trigram(row):\n",
    "    idx = row.name\n",
    "    return [tfidf for tfidf in tfidf_mat_trigram if tfidf != 0.0]\n",
    "\n",
    "TWEET_DATA[\"TFIDF_trigram\"] = TWEET_DATA.apply(get_TF_trigram, axis=1)\n",
    "\n",
    "TWEET_DATA[[\"tweet\", \"TF_trigram\", \"IDF_trigram\", \"TFIDF_trigram\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save TFIDF Trigram to Excel\n",
    "\n",
    "TWEET_DATA[[\"tweet\", \"TF_trigram\", \"IDF_trigram\", \"TFIDF_trigram\"]].to_excel(\"TFIDF_Trigram.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
