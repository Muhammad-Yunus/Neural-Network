{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"RT @mas__piyuuu: Bantu Bekasi, Anies Baswedan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"@LisaAmartatara3 @fadlizon Yg dibangga bangga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"RT @RustamIbrahim: POLLING: Dari 4 gubernur d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"ojok ampe Anies Baswedan menikmati hsil proye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"RT @ghanieierfan: Pertemuan sangat mengharuka...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  \"RT @mas__piyuuu: Bantu Bekasi, Anies Baswedan...      0\n",
       "1  \"@LisaAmartatara3 @fadlizon Yg dibangga bangga...      1\n",
       "2  \"RT @RustamIbrahim: POLLING: Dari 4 gubernur d...      1\n",
       "3  \"ojok ampe Anies Baswedan menikmati hsil proye...      1\n",
       "4  \"RT @ghanieierfan: Pertemuan sangat mengharuka...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "TWEET_DATA = pd.read_csv(\"dataset_sementara.csv\", encoding = \"ISO-8859-1\")\n",
    "\n",
    "TWEET_DATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Folding Result : \n",
      "\n",
      "0    \"rt @mas__piyuuu: bantu bekasi, anies baswedan...\n",
      "1    \"@lisaamartatara3 @fadlizon yg dibangga bangga...\n",
      "2    \"rt @rustamibrahim: polling: dari 4 gubernur d...\n",
      "3    \"ojok ampe anies baswedan menikmati hsil proye...\n",
      "4    \"rt @ghanieierfan: pertemuan sangat mengharuka...\n",
      "Name: tweet, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------ Case Folding --------\n",
    "# gunakan fungsi Series.str.lower() pada Pandas\n",
    "TWEET_DATA['tweet'] = TWEET_DATA['tweet'].str.lower()\n",
    "\n",
    "\n",
    "print('Case Folding Result : \\n')\n",
    "print(TWEET_DATA['tweet'].head(5))\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Result : \n",
      "\n",
      "0    [rt, maspiyuuu, bantu, bekasi, anies, baswedan...\n",
      "1    [lisaamartatara, fadlizon, yg, dibangga, bangg...\n",
      "2    [rt, rustamibrahim, polling, dari, gubernur, d...\n",
      "3    [ojok, ampe, anies, baswedan, menikmati, hsil,...\n",
      "4    [rt, ghanieierfan, pertemuan, sangat, mengharu...\n",
      "Name: tweet_tokens, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import re #regex library\n",
    "\n",
    "# import word_tokenize & FreqDist from NLTK\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# ------ Tokenizing ---------\n",
    "#remove number\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "TWEET_DATA['tweet'] = TWEET_DATA['tweet'].apply(remove_number)\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "TWEET_DATA['tweet'] = TWEET_DATA['tweet'].apply(remove_punctuation)\n",
    "\n",
    "#remove whitespace leading & trailing\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "TWEET_DATA['tweet'] = TWEET_DATA['tweet'].apply(remove_whitespace_LT)\n",
    "\n",
    "#remove multiple whitespace into single whitespace\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "TWEET_DATA['tweet'] = TWEET_DATA['tweet'].apply(remove_whitespace_multiple)\n",
    "\n",
    "\n",
    "# NLTK word rokenize \n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "TWEET_DATA['tweet_tokens'] = TWEET_DATA['tweet'].apply(word_tokenize_wrapper)\n",
    "\n",
    "print('Tokenizing Result : \\n') \n",
    "print(TWEET_DATA['tweet_tokens'].head())\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Tokens : \n",
      "\n",
      "0    [(rt, 1), (maspiyuuu, 1), (bantu, 1), (bekasi,...\n",
      "1    [(lisaamartatara, 1), (fadlizon, 1), (yg, 1), ...\n",
      "2    [(rt, 1), (rustamibrahim, 1), (polling, 1), (d...\n",
      "3    [(ojok, 1), (ampe, 1), (anies, 1), (baswedan, ...\n",
      "4    [(rt, 1), (ghanieierfan, 1), (pertemuan, 1), (...\n",
      "Name: tweet_tokens_fdist, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# NLTK calc frequency distribution\n",
    "def freqDist_wrapper(text):\n",
    "    return FreqDist(text)\n",
    "\n",
    "TWEET_DATA['tweet_tokens_fdist'] = TWEET_DATA['tweet_tokens'].apply(freqDist_wrapper)\n",
    "\n",
    "print('Frequency Tokens : \\n') \n",
    "print(TWEET_DATA['tweet_tokens_fdist'].head().apply(lambda x : x.most_common()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.2 ms ± 2.85 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "0    [maspiyuuu, bantu, bekasi, anies, baswedan, me...\n",
      "1    [lisaamartatara, fadlizon, dibangga, banggain,...\n",
      "2    [rustamibrahim, polling, gubernur, jawa, ridwa...\n",
      "3    [ojok, ampe, anies, baswedan, menikmati, hsil,...\n",
      "4    [ghanieierfan, pertemuan, mengharukan, aniesba...\n",
      "Name: tweet_tokens_fdist_WSW, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# get stopword indonesia\n",
    "list_stopwords = stopwords.words('indonesian')\n",
    "\n",
    "# append additional stopword\n",
    "list_stopwords.extend([\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo', 'kalo', 'amp', 'biar', 'bikin', 'bilang', 'gak', 'ga', 'krn', 'nya', 'nih', 'sih', 'si', 'tau', 'tdk', 'tuh', 'utk', 'ya', 'jd', 'jgn', 'sdh', 'aja'])\n",
    "\n",
    "list_stopwords = set(list_stopwords)\n",
    "\n",
    "#remove stopword pada list token\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if not word in list_stopwords]\n",
    "\n",
    "%timeit TWEET_DATA['tweet_tokens_fdist_WSW'] = TWEET_DATA['tweet_tokens_fdist'].apply(stopwords_removal) \n",
    "\n",
    "\n",
    "print(TWEET_DATA['tweet_tokens_fdist_WSW'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65138\n",
      "------------------------\n",
      "maspiyuuu : maspiyuuu\n",
      "bantu : bantu\n",
      "bekasi : bekas\n",
      "anies : anies\n",
      "baswedan : baswedan\n",
      "melayani : layan\n",
      "warga : warga\n",
      "negara : negara\n",
      "indonesia : indonesia\n",
      "httpstcobiwxvhsvknntinggal : httpstcobiwxvhsvknntinggal\n",
      "dilantik : lantik\n",
      "inimah : inimah\n",
      "pru : pru\n",
      "lisaamartatara : lisaamartatara\n",
      "fadlizon : fadlizon\n",
      "dibangga : bangga\n",
      "banggain : banggain\n",
      "buzzer : buzzer\n",
      "cendana : cendana\n",
      "yah : yah\n",
      "cuman : cuman\n",
      "orangn : orangn\n",
      "alm : alm\n",
      "soeharton : soeharton\n",
      "baswedannyg : baswedannyg\n",
      "lewathehe : lewathehe\n",
      "rustamibrahim : rustamibrahim\n",
      "polling : polling\n",
      "gubernur : gubernur\n",
      "jawa : jawa\n",
      "ridwan : ridwan\n",
      "kamil : kamil\n",
      "ganjar : ganjar\n",
      "pranowo : pranowo\n",
      "khofifah : khofifah\n",
      "indar : indar\n",
      "parawansa : parawansa\n",
      "penu : penu\n",
      "ojok : ojok\n",
      "ampe : ampe\n",
      "menikmati : nikmat\n",
      "hsil : hsil\n",
      "proyek : proyek\n",
      "monas : monas\n",
      "yng : yng\n",
      "penuh : penuh\n",
      "kejanggalannya : janggal\n",
      "usutskandalmonasgate : usutskandalmonasgate\n",
      "ghanieierfan : ghanieierfan\n",
      "pertemuan : temu\n",
      "mengharukan : haru\n",
      "aniesbaswedan : aniesbaswedan\n",
      "tsuneo : tsuneo\n",
      "yamada : yamada\n",
      "orang : orang\n",
      "tua : tua\n",
      "angkat : angkat\n",
      "goodbener : goodbener\n",
      "kuliah : kuliah\n",
      "sophia : sophia\n",
      "univeu : univeu\n",
      "sebastianteza : sebastianteza\n",
      "jangn : jangn\n",
      "nympek : nympek\n",
      "hsl : hsl\n",
      "tamastefan : tamastefan\n",
      "mencapai : capai\n",
      "produk : produk\n",
      "cetak : cetak\n",
      "biru : biru\n",
      "monumen : monumen\n",
      "nasional : nasional\n",
      "nan : nan\n",
      "tumpat : tumpat\n",
      "usutskandalmou : usutskandalmou\n",
      "ariestariico : ariestariico\n",
      "niat : niat\n",
      "cari : cari\n",
      "prestasi : prestasi\n",
      "ilegal : ilegal\n",
      "kuasai : kuasa\n",
      "revitalisasinusutskandalmonasgateu : revitalisasinusutskandalmonasgateu\n",
      "berbatas : batas\n",
      "rakitan : rakit\n",
      "memadai : pada\n",
      "santorotahir : santorotahir\n",
      "jagan : jagan\n",
      "nyampe : nyampe\n",
      "mpe : mpe\n",
      "putranafil : putranafil\n",
      "buatan : buat\n",
      "desain : desain\n",
      "tamam : tamam\n",
      "nurulllputrii : nurulllputrii\n",
      "jakarta : jakarta\n",
      "salinguamenopang : salinguamenopang\n",
      "httpstcozdzrkdr : httpstcozdzrkdr\n",
      "httpstcousnism : httpstcousnism\n",
      "penyukaombak : penyukaombak\n",
      "lohhkenapa : lohhkenapa\n",
      "yannjangan : yannjangan\n",
      "pohon : pohon\n",
      "mahoni : mahoni\n",
      "tebang : tebang\n",
      "ordernilai : ordernilai\n",
      "m : m\n",
      "gaess : gaess\n",
      "stelau : stelau\n",
      "rencana : rencana\n",
      "purnama : purnama\n",
      "ngancel : ngancel\n",
      "bangun : bangun\n",
      "citra : citra\n",
      "beautifikasi : beautifikasi\n",
      "tata : tata\n",
      "aturan : atur\n",
      "ditabrak : tabrak\n",
      "komunikasi : komunikasi\n",
      "buruk : buruk\n",
      "bukit : bukit\n",
      "ketidakseriusanu : ketidakseriusanu\n",
      "geiszchalifah : geiszchalifah\n",
      "banjir : banjir\n",
      "disalahkan : salah\n",
      "mrk : mrk\n",
      "udik : udik\n",
      "faham : faham\n",
      "peta : peta\n",
      "nkali : nkali\n",
      "pemrov : pemrov\n",
      "dki : dki\n",
      "flyou : flyou\n",
      "maksimum : maksimum\n",
      "ojo : ojo\n",
      "aniesupdatenews : aniesupdatenews\n",
      "resmikan : resmi\n",
      "flyover : flyover\n",
      "senilai : nila\n",
      "rp : rp\n",
      "miliarnnbukan : miliarnnbukan\n",
      "penyangga : sangga\n",
      "peu : peu\n",
      "valenciavicr : valenciavicr\n",
      "permasalahan : masalah\n",
      "akibat : akibat\n",
      "mengerti : erti\n",
      "kelola : kelola\n",
      "wilayah : wilayah\n",
      "nnusutskandalmonasgate : nnusutskandalmonasgate\n",
      "httpstcobmu : httpstcobmu\n",
      "jngan : jngan\n",
      "jennitalala : jennitalala\n",
      "kaya : kaya\n",
      "musniumar : musniumar\n",
      "googlenews : googlenews\n",
      "timpang : timpang\n",
      "tindih : tindih\n",
      "kepentingan : penting\n",
      "seputaran : putar\n",
      "dijadikan : jadi\n",
      "senjata : senjata\n",
      "membunuh : bunuh\n",
      "karakter : karakter\n",
      "lafizaj : lafizaj\n",
      "pesanan : pesan\n",
      "pol : pol\n",
      "putriiiindaah : putriiiindaah\n",
      "usutskandalmonasgau : usutskandalmonasgau\n",
      "mantap : mantap\n",
      "httpstcojutjtx : httpstcojutjtx\n",
      "putrialison : putrialison\n",
      "jngn : jngn\n",
      "cak : cak\n",
      "order : order\n",
      "sempurna : sempurna\n",
      "rgfansclub : rgfansclub\n",
      "ketentraman : ketentraman\n",
      "berwarganegara : berwarganegara\n",
      "hilang : hilang\n",
      "keadilan : adil\n",
      "hukum : hukum\n",
      "ham : ham\n",
      "kepekaan : peka\n",
      "sosial : sosial\n",
      "rentetan : rentet\n",
      "hancur : hancur\n",
      "solusi : solusi\n",
      "segalau : galau\n",
      "subhanmaulana : subhanmaulana\n",
      "usutskandau : usutskandau\n",
      "arilestari : arilestari\n",
      "semoga : moga\n",
      "kali : kali\n",
      "kena : kena\n",
      "batunya : batu\n",
      "n : n\n",
      "lolos : lolos\n",
      "laginnhttpstcorulvqcfds : laginnhttpstcorulvqcfds\n",
      "httpstcolnbxzogpzw : httpstcolnbxzogpzw\n",
      "anangfirmansss : anangfirmansss\n",
      "julietrohman : julietrohman\n",
      "usutskandalmu : usutskandalmu\n",
      "djangan : djangan\n",
      "oktavinia : oktavinia\n",
      "andrcici : andrcici\n",
      "regidian : regidian\n",
      "alanpradipto : alanpradipto\n",
      "proposal : proposal\n",
      "peres : peres\n",
      "usutskandalmonau : usutskandalmonau\n",
      "akbarironako : akbarironako\n",
      "sampek : sampek\n",
      "rozergilang : rozergilang\n",
      "kancap : kancap\n",
      "usutskandalmonu : usutskandalmonu\n",
      "syandanataki : syandanataki\n",
      "rgfansofficial : rgfansofficial\n",
      "pangan : pangan\n",
      "disubsidi : subsidi\n",
      "aniesnberas : aniesnberas\n",
      "rbkgndaging : rbkgndaging\n",
      "sapi : sapi\n",
      "rbkgntelur : rbkgntelur\n",
      "ayam : ayam\n",
      "rbtrayndagu : rbtrayndagu\n",
      "natasyaelviras : natasyaelviras\n",
      "padat : padat\n",
      "ratnadedw : ratnadedw\n",
      "rosaaprilliaa : rosaaprilliaa\n",
      "hasil : hasil\n",
      "masuk : masuk\n",
      "peresmiannya : resmi\n",
      "terlepas : lepas\n",
      "dana : dana\n",
      "hibah : hibah\n",
      "pemprov : pemprov\n",
      "bukannnridwankamil : bukannnridwankamil\n",
      "aniesbaswedannhttpstcosnrpxov : aniesbaswedannhttpstcosnrpxov\n",
      "herucatur : herucatur\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-65019635e320>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mterm_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mterm_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstemmed_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\":\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mterm_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-65019635e320>\u001b[0m in \u001b[0;36mstemmed_wrapper\u001b[1;34m(term)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# stemmed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstemmed_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mterm_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ROOT\\lib\\site-packages\\Sastrawi\\Stemmer\\CachedStemmer.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mstems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelegatedStemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mstems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ROOT\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mstems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ROOT\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py\u001b[0m in \u001b[0;36mstem_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem_plural_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem_singular_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_plural\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ROOT\\lib\\site-packages\\Sastrawi\\Stemmer\\Stemmer.py\u001b[0m in \u001b[0;36mstem_singular_word\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;34m\"\"\"Stem a singular word to its common stem form.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisitor_provider\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ROOT\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m#step 1 - 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_stemming_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#step 6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ROOT\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36mstart_stemming_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;31m#step 4, 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_prefixes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ROOT\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36mremove_prefixes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mremove_prefixes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccept_prefix_visitors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefix_pisitors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ROOT\\lib\\site-packages\\Sastrawi\\Stemmer\\Context\\Context.py\u001b[0m in \u001b[0;36maccept_prefix_visitors\u001b[1;34m(self, visitors)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvisitor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvisitors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisitor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_is_stopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import Sastrawi package\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import swifter\n",
    "\n",
    "\n",
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# stemmed\n",
    "def stemmed_wrapper(term):\n",
    "    return stemmer.stem(term)\n",
    "\n",
    "term_dict = {}\n",
    "\n",
    "for document in TWEET_DATA['tweet_tokens_fdist_WSW']:\n",
    "    for term in document:\n",
    "        if term not in term_dict:\n",
    "            term_dict[term] = ' '\n",
    "            \n",
    "print(len(term_dict))\n",
    "print(\"------------------------\")\n",
    "\n",
    "for term in term_dict:\n",
    "    term_dict[term] = stemmed_wrapper(term)\n",
    "    print(term,\":\" ,term_dict[term])\n",
    "    \n",
    "print(term_dict)\n",
    "print(\"------------------------\")\n",
    "\n",
    "\n",
    "# apply stemmed term to dataframe\n",
    "def get_stemmed_term(document):\n",
    "    return [term_dict[term] for term in document]\n",
    "\n",
    "TWEET_DATA['tweet_tokens_stemmed'] = TWEET_DATA['tweet_tokens_fdist_WSW'].swifter.apply(get_stemmed_term)\n",
    "print(TWEET_DATA['tweet_tokens_stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEET_DATA.to_csv(\"Text_Preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEET_DATA.to_excel(\"Text_Preprocessing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEET_DATA.to_hdf(\"Text_Preprocessing.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
